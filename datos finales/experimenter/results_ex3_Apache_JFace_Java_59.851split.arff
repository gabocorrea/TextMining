@relation InstanceResultListener

@attribute Key_Dataset {3_Apache_JFace_Java.arff}
@attribute Key_Run {1}
@attribute Key_Scheme {weka.classifiers.meta.FilteredClassifier}
@attribute Key_Scheme_options {'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial'}
@attribute Key_Scheme_version_ID {-4523450618538717400}
@attribute Date_time numeric
@attribute Number_of_training_instances numeric
@attribute Number_of_testing_instances numeric
@attribute Number_correct numeric
@attribute Number_incorrect numeric
@attribute Number_unclassified numeric
@attribute Percent_correct numeric
@attribute Percent_incorrect numeric
@attribute Percent_unclassified numeric
@attribute Kappa_statistic numeric
@attribute Mean_absolute_error numeric
@attribute Root_mean_squared_error numeric
@attribute Relative_absolute_error numeric
@attribute Root_relative_squared_error numeric
@attribute SF_prior_entropy numeric
@attribute SF_scheme_entropy numeric
@attribute SF_entropy_gain numeric
@attribute SF_mean_prior_entropy numeric
@attribute SF_mean_scheme_entropy numeric
@attribute SF_mean_entropy_gain numeric
@attribute KB_information numeric
@attribute KB_mean_information numeric
@attribute KB_relative_information numeric
@attribute True_positive_rate numeric
@attribute Num_true_positives numeric
@attribute False_positive_rate numeric
@attribute Num_false_positives numeric
@attribute True_negative_rate numeric
@attribute Num_true_negatives numeric
@attribute False_negative_rate numeric
@attribute Num_false_negatives numeric
@attribute IR_precision numeric
@attribute IR_recall numeric
@attribute F_measure numeric
@attribute Area_under_ROC numeric
@attribute Weighted_avg_true_positive_rate numeric
@attribute Weighted_avg_false_positive_rate numeric
@attribute Weighted_avg_true_negative_rate numeric
@attribute Weighted_avg_false_negative_rate numeric
@attribute Weighted_avg_IR_precision numeric
@attribute Weighted_avg_IR_recall numeric
@attribute Weighted_avg_F_measure numeric
@attribute Weighted_avg_area_under_ROC numeric
@attribute Elapsed_Time_training numeric
@attribute Elapsed_Time_testing numeric
@attribute UserCPU_Time_training numeric
@attribute UserCPU_Time_testing numeric
@attribute Serialized_Model_Size numeric
@attribute Serialized_Train_Set_Size numeric
@attribute Serialized_Test_Set_Size numeric
@attribute Summary string

@data

3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1836,3533,2370,1887,483,0,79.620253,20.379747,0,0.522377,0.212661,0.408189,60.225575,87.64472,2188.47936,2937.901425,-749.422065,0.923409,1.239621,-0.316212,725.706774,0.306205,113279.600549,0.726457,486,0.176367,300,0.823633,1401,0.273543,183,0.618321,0.726457,0.668041,0.861197,0.796203,0.246112,0.753888,0.203797,0.809342,0.796203,0.800767,0.861197,2.276,5.386,2.215214,4.66443,441582,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1836,3533,2370,1887,483,0,79.620253,20.379747,0,0.522377,0.212661,0.408189,60.225575,87.64472,2188.47936,2937.901425,-749.422065,0.923409,1.239621,-0.316212,725.706774,0.306205,113279.600549,0.726457,486,0.176367,300,0.823633,1401,0.273543,183,0.618321,0.726457,0.668041,0.861197,0.796203,0.246112,0.753888,0.203797,0.809342,0.796203,0.800767,0.861197,2.31,5.341,2.215214,4.68003,441624,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1836,3533,2370,1940,430,0,81.85654,18.14346,0,0.545636,0.196973,0.382112,55.782745,82.045449,2188.47936,2103.945607,84.533753,0.923409,0.887741,0.035668,883.093637,0.372613,137846.990039,0.654709,438,0.11699,199,0.88301,1502,0.345291,231,0.687598,0.654709,0.67075,0.858554,0.818565,0.280847,0.719153,0.181435,0.816147,0.818565,0.817188,0.858554,2.028,5.263,1.981213,4.555229,434733,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1836,3533,2370,1940,430,0,81.85654,18.14346,0,0.545636,0.196973,0.382112,55.782745,82.045449,2188.47936,2103.945607,84.533753,0.923409,0.887741,0.035668,883.093637,0.372613,137846.990039,0.654709,438,0.11699,199,0.88301,1502,0.345291,231,0.687598,0.654709,0.67075,0.858554,0.818565,0.280847,0.719153,0.181435,0.816147,0.818565,0.817188,0.858554,2.064,5.177,2.028013,4.570829,434775,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1836,3533,2370,1881,489,0,79.367089,20.632911,0,0.512243,0.213247,0.424811,60.391615,91.213598,2188.47936,16512.528205,-14324.048845,0.923409,6.967311,-6.043902,733.02589,0.309294,114422.082074,0.707025,473,0.172252,293,0.827748,1408,0.292975,196,0.617493,0.707025,0.659233,0.839685,0.793671,0.258897,0.741103,0.206329,0.804325,0.793671,0.797617,0.839996,2.265,5.42,2.246414,4.72683,441584,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1836,3533,2370,1881,489,0,79.367089,20.632911,0,0.512243,0.213247,0.424811,60.391615,91.213598,2188.47936,16512.528205,-14324.048845,0.923409,6.967311,-6.043902,733.02589,0.309294,114422.082074,0.707025,473,0.172252,293,0.827748,1408,0.292975,196,0.617493,0.707025,0.659233,0.839685,0.793671,0.258897,0.741103,0.206329,0.804325,0.793671,0.797617,0.839996,2.2,5.387,2.106014,4.758031,441626,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1911,459,0,80.632911,19.367089,0,0.512525,0.204107,0.399466,57.80318,85.771703,2188.47936,9634.198913,-7445.719553,0.923409,4.065063,-3.141654,829.200461,0.349874,129434.504939,0.624813,418,0.122281,208,0.877719,1493,0.375187,251,0.667732,0.624813,0.64556,0.842157,0.806329,0.303797,0.696203,0.193671,0.802912,0.806329,0.804322,0.842259,2.218,5.226,2.106014,4.60203,434735,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1911,459,0,80.632911,19.367089,0,0.512525,0.204107,0.399466,57.80318,85.771703,2188.47936,9634.198913,-7445.719553,0.923409,4.065063,-3.141654,829.200461,0.349874,129434.504939,0.624813,418,0.122281,208,0.877719,1493,0.375187,251,0.667732,0.624813,0.64556,0.842157,0.806329,0.303797,0.696203,0.193671,0.802912,0.806329,0.804322,0.842259,2.018,5.227,1.965613,4.570829,434777,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1887,483,0,79.620253,20.379747,0,0.522377,0.212661,0.408189,60.225575,87.64472,2188.47936,2937.901425,-749.422065,0.923409,1.239621,-0.316212,725.706774,0.306205,113279.600549,0.726457,486,0.176367,300,0.823633,1401,0.273543,183,0.618321,0.726457,0.668041,0.861197,0.796203,0.246112,0.753888,0.203797,0.809342,0.796203,0.800767,0.861197,2.217,5.371,2.121614,4.64883,441586,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1887,483,0,79.620253,20.379747,0,0.522377,0.212661,0.408189,60.225575,87.64472,2188.47936,2937.901425,-749.422065,0.923409,1.239621,-0.316212,725.706774,0.306205,113279.600549,0.726457,486,0.176367,300,0.823633,1401,0.273543,183,0.618321,0.726457,0.668041,0.861197,0.796203,0.246112,0.753888,0.203797,0.809342,0.796203,0.800767,0.861197,2.263,5.355,2.215214,4.64883,441628,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1940,430,0,81.85654,18.14346,0,0.545636,0.196973,0.382112,55.782745,82.045449,2188.47936,2103.945607,84.533753,0.923409,0.887741,0.035668,883.093637,0.372613,137846.990039,0.654709,438,0.11699,199,0.88301,1502,0.345291,231,0.687598,0.654709,0.67075,0.858554,0.818565,0.280847,0.719153,0.181435,0.816147,0.818565,0.817188,0.858554,2.122,5.528,1.996813,4.60203,434737,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1940,430,0,81.85654,18.14346,0,0.545636,0.196973,0.382112,55.782745,82.045449,2188.47936,2103.945607,84.533753,0.923409,0.887741,0.035668,883.093637,0.372613,137846.990039,0.654709,438,0.11699,199,0.88301,1502,0.345291,231,0.687598,0.654709,0.67075,0.858554,0.818565,0.280847,0.719153,0.181435,0.816147,0.818565,0.817188,0.858554,2.153,5.666,2.074813,4.851631,434779,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1836,534,0,77.468354,22.531646,0,0.481106,0.230939,0.453517,65.401825,97.377182,2188.47936,21666.249909,-19477.770549,0.923409,9.141878,-8.218469,606.282443,0.255815,94637.993448,0.718984,481,0.20341,346,0.79659,1355,0.281016,188,0.58162,0.718984,0.643048,0.802864,0.774684,0.25911,0.74089,0.225316,0.794453,0.774684,0.781095,0.802954,2.34,5.632,2.230814,4.74243,441588,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1837,3533,2370,1836,534,0,77.468354,22.531646,0,0.481106,0.230939,0.453517,65.401825,97.377182,2188.47936,21666.249909,-19477.770549,0.923409,9.141878,-8.218469,606.282443,0.255815,94637.993448,0.718984,481,0.20341,346,0.79659,1355,0.281016,188,0.58162,0.718984,0.643048,0.802864,0.774684,0.25911,0.74089,0.225316,0.794453,0.774684,0.781095,0.802954,2.406,5.528,2.324415,4.74243,441630,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1838,3533,2370,1878,492,0,79.240506,20.759494,0,0.482029,0.216154,0.429433,61.214857,92.205967,2188.47936,17188.590275,-15000.110915,0.923409,7.25257,-6.329161,729.201509,0.30768,113825.113079,0.61435,411,0.137566,234,0.862434,1467,0.38565,258,0.637209,0.61435,0.625571,0.80038,0.792405,0.315621,0.684379,0.207595,0.790246,0.792405,0.791236,0.800587,2.09,5.184,2.028013,4.71123,434739,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1838,3533,2370,1878,492,0,79.240506,20.759494,0,0.482029,0.216154,0.429433,61.214857,92.205967,2188.47936,17188.590275,-15000.110915,0.923409,7.25257,-6.329161,729.201509,0.30768,113825.113079,0.61435,411,0.137566,234,0.862434,1467,0.38565,258,0.637209,0.61435,0.625571,0.80038,0.792405,0.315621,0.684379,0.207595,0.790246,0.792405,0.791236,0.800587,2.091,5.136,2.012413,4.508429,434781,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1944,426,0,82.025316,17.974684,0,0.511665,0.203716,0.381292,57.692279,81.869367,2188.47936,2005.414833,183.064528,0.923409,0.846167,0.077242,853.788426,0.360248,133272.576916,0.530643,355,0.065844,112,0.934156,1589,0.469357,314,0.760171,0.530643,0.625,0.844442,0.820253,0.355454,0.644546,0.179747,0.813876,0.820253,0.809309,0.844442,0.135,0.064,0.109201,0.0468,239470,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1944,426,0,82.025316,17.974684,0,0.511665,0.203716,0.381292,57.692279,81.869367,2188.47936,2005.414833,183.064528,0.923409,0.846167,0.077242,853.788426,0.360248,133272.576916,0.530643,355,0.065844,112,0.934156,1589,0.469357,314,0.760171,0.530643,0.625,0.844442,0.820253,0.355454,0.644546,0.179747,0.813876,0.820253,0.809309,0.844442,0.135,0.059,0.124801,0.0624,239512,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1947,423,0,82.151899,17.848101,0,0.515829,0.207962,0.377459,58.894828,81.046478,2188.47936,1900.472734,288.006626,0.923409,0.801887,0.121522,830.941341,0.350608,129706.248576,0.535127,358,0.065844,112,0.934156,1589,0.464873,311,0.761702,0.535127,0.628622,0.842106,0.821519,0.352236,0.647764,0.178481,0.815254,0.821519,0.810859,0.842106,0.105,0.123,0.109201,0.0468,236037,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1947,423,0,82.151899,17.848101,0,0.515829,0.207962,0.377459,58.894828,81.046478,2188.47936,1900.472734,288.006626,0.923409,0.801887,0.121522,830.941341,0.350608,129706.248576,0.535127,358,0.065844,112,0.934156,1589,0.464873,311,0.761702,0.535127,0.628622,0.842106,0.821519,0.352236,0.647764,0.178481,0.815254,0.821519,0.810859,0.842106,0.109,0.063,0.093601,0.0468,236079,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1932,438,0,81.518987,18.481013,0,0.503363,0.204763,0.387555,57.988782,83.214139,2188.47936,2274.244369,-85.765008,0.923409,0.959597,-0.036188,838.743082,0.3539,130924.065605,0.538117,360,0.075838,129,0.924162,1572,0.461883,309,0.736196,0.538117,0.621762,0.826198,0.81519,0.352911,0.647089,0.18481,0.807631,0.81519,0.80547,0.826198,0.11,0.063,0.109201,0.0624,239472,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1932,438,0,81.518987,18.481013,0,0.503363,0.204763,0.387555,57.988782,83.214139,2188.47936,2274.244369,-85.765008,0.923409,0.959597,-0.036188,838.743082,0.3539,130924.065605,0.538117,360,0.075838,129,0.924162,1572,0.461883,309,0.736196,0.538117,0.621762,0.826198,0.81519,0.352911,0.647089,0.18481,0.807631,0.81519,0.80547,0.826198,0.109,0.062,0.093601,0.0468,239514,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1945,425,0,82.067511,17.932489,0,0.517388,0.207135,0.379825,58.660671,81.554418,2188.47936,2085.800487,102.678874,0.923409,0.880085,0.043324,830.730998,0.350519,129673.414866,0.54559,365,0.071135,121,0.928865,1580,0.45441,304,0.751029,0.54559,0.632035,0.831217,0.820675,0.346219,0.653781,0.179325,0.81391,0.820675,0.811046,0.831217,0.11,0.046,0.093601,0.0468,236039,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1945,425,0,82.067511,17.932489,0,0.517388,0.207135,0.379825,58.660671,81.554418,2188.47936,2085.800487,102.678874,0.923409,0.880085,0.043324,830.730998,0.350519,129673.414866,0.54559,365,0.071135,121,0.928865,1580,0.45441,304,0.751029,0.54559,0.632035,0.831217,0.820675,0.346219,0.653781,0.179325,0.81391,0.820675,0.811046,0.831217,0.094,0.047,0.078001,0.0468,236081,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1820,550,0,76.793249,23.206751,0,0.427788,0.235149,0.461926,66.59416,99.182739,2188.47936,8882.321659,-6693.842298,0.923409,3.747815,-2.824406,573.802112,0.242111,89567.958198,0.590433,395,0.162257,276,0.837743,1425,0.409567,274,0.588674,0.590433,0.589552,0.759856,0.767932,0.339757,0.660243,0.232068,0.768144,0.767932,0.768037,0.759871,0.109,0.078,0.109201,0.0624,239474,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1820,550,0,76.793249,23.206751,0,0.427788,0.235149,0.461926,66.59416,99.182739,2188.47936,8882.321659,-6693.842298,0.923409,3.747815,-2.824406,573.802112,0.242111,89567.958198,0.590433,395,0.162257,276,0.837743,1425,0.409567,274,0.588674,0.590433,0.589552,0.759856,0.767932,0.339757,0.660243,0.232068,0.768144,0.767932,0.768037,0.759871,0.125,0.063,0.109201,0.0468,239516,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1809,561,0,76.329114,23.670886,0,0.418714,0.23787,0.463071,67.364867,99.428686,2188.47936,8808.872729,-6620.393368,0.923409,3.716824,-2.793415,555.441799,0.234364,86701.995006,0.588939,394,0.168136,286,0.831864,1415,0.411061,275,0.579412,0.588939,0.584136,0.756834,0.763291,0.342489,0.657511,0.236709,0.764488,0.763291,0.763872,0.756847,0.109,0.047,0.093601,0.0312,236041,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1809,561,0,76.329114,23.670886,0,0.418714,0.23787,0.463071,67.364867,99.428686,2188.47936,8808.872729,-6620.393368,0.923409,3.716824,-2.793415,555.441799,0.234364,86701.995006,0.588939,394,0.168136,286,0.831864,1415,0.411061,275,0.579412,0.588939,0.584136,0.756834,0.763291,0.342489,0.657511,0.236709,0.764488,0.763291,0.763872,0.756847,0.109,0.062,0.109201,0.0624,236083,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1818,552,0,76.708861,23.291139,0,0.425186,0.232988,0.461147,65.982155,99.015474,2188.47936,9533.139624,-7344.660263,0.923409,4.022422,-3.099013,590.367632,0.2491,92153.762292,0.587444,393,0.162257,276,0.837743,1425,0.412556,276,0.587444,0.587444,0.587444,0.75638,0.767089,0.341902,0.658098,0.232911,0.767089,0.767089,0.767089,0.756443,0.172,0.062,0.093601,0.0624,239476,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1818,552,0,76.708861,23.291139,0,0.425186,0.232988,0.461147,65.982155,99.015474,2188.47936,9533.139624,-7344.660263,0.923409,4.022422,-3.099013,590.367632,0.2491,92153.762292,0.587444,393,0.162257,276,0.837743,1425,0.412556,276,0.587444,0.587444,0.587444,0.75638,0.767089,0.341902,0.658098,0.232911,0.767089,0.767089,0.767089,0.756443,0.109,0.063,0.093601,0.0468,239518,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1809,561,0,76.329114,23.670886,0,0.419238,0.237593,0.464278,67.28635,99.687914,2188.47936,9436.016362,-7247.537002,0.923409,3.981442,-3.058032,559.9636,0.236272,87407.828026,0.590433,395,0.168724,287,0.831276,1414,0.409567,274,0.579179,0.590433,0.584752,0.752122,0.763291,0.341582,0.658418,0.236709,0.764709,0.763291,0.763976,0.752207,0.109,0.062,0.109201,0.0624,236043,612526,560191,?
3_Apache_JFace_Java.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1838,3533,2370,1809,561,0,76.329114,23.670886,0,0.419238,0.237593,0.464278,67.28635,99.687914,2188.47936,9436.016362,-7247.537002,0.923409,3.981442,-3.058032,559.9636,0.236272,87407.828026,0.590433,395,0.168724,287,0.831276,1414,0.409567,274,0.579179,0.590433,0.584752,0.752122,0.763291,0.341582,0.658418,0.236709,0.764709,0.763291,0.763976,0.752207,0.11,0.046,0.109201,0.0468,236085,612526,560191,?

@relation InstanceResultListener

@attribute Key_Dataset {3_Apache_Java_JFace.arff}
@attribute Key_Run {1}
@attribute Key_Scheme {weka.classifiers.meta.FilteredClassifier}
@attribute Key_Scheme_options {'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial'}
@attribute Key_Scheme_version_ID {-4523450618538717400}
@attribute Date_time numeric
@attribute Number_of_training_instances numeric
@attribute Number_of_testing_instances numeric
@attribute Number_correct numeric
@attribute Number_incorrect numeric
@attribute Number_unclassified numeric
@attribute Percent_correct numeric
@attribute Percent_incorrect numeric
@attribute Percent_unclassified numeric
@attribute Kappa_statistic numeric
@attribute Mean_absolute_error numeric
@attribute Root_mean_squared_error numeric
@attribute Relative_absolute_error numeric
@attribute Root_relative_squared_error numeric
@attribute SF_prior_entropy numeric
@attribute SF_scheme_entropy numeric
@attribute SF_entropy_gain numeric
@attribute SF_mean_prior_entropy numeric
@attribute SF_mean_scheme_entropy numeric
@attribute SF_mean_entropy_gain numeric
@attribute KB_information numeric
@attribute KB_mean_information numeric
@attribute KB_relative_information numeric
@attribute True_positive_rate numeric
@attribute Num_true_positives numeric
@attribute False_positive_rate numeric
@attribute Num_false_positives numeric
@attribute True_negative_rate numeric
@attribute Num_true_negatives numeric
@attribute False_negative_rate numeric
@attribute Num_false_negatives numeric
@attribute IR_precision numeric
@attribute IR_recall numeric
@attribute F_measure numeric
@attribute Area_under_ROC numeric
@attribute Weighted_avg_true_positive_rate numeric
@attribute Weighted_avg_false_positive_rate numeric
@attribute Weighted_avg_true_negative_rate numeric
@attribute Weighted_avg_false_negative_rate numeric
@attribute Weighted_avg_IR_precision numeric
@attribute Weighted_avg_IR_recall numeric
@attribute Weighted_avg_F_measure numeric
@attribute Weighted_avg_area_under_ROC numeric
@attribute Elapsed_Time_training numeric
@attribute Elapsed_Time_testing numeric
@attribute UserCPU_Time_training numeric
@attribute UserCPU_Time_testing numeric
@attribute Serialized_Model_Size numeric
@attribute Serialized_Train_Set_Size numeric
@attribute Serialized_Test_Set_Size numeric
@attribute Summary string

@data

3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1827,3993,1910,1513,397,0,79.21466,20.78534,0,0.295077,0.215569,0.422043,89.768481,147.02077,882.685521,2712.04412,-1829.358598,0.462139,1.419918,-0.957779,-237.151488,-0.124163,-33197.995195,0.862319,119,0.213318,378,0.786682,1394,0.137681,19,0.239437,0.862319,0.374803,0.907331,0.792147,0.143146,0.856854,0.207853,0.932573,0.792147,0.839188,0.907331,2.686,4.154,2.574017,3.494422,407020,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1827,3993,1910,1513,397,0,79.21466,20.78534,0,0.295077,0.215569,0.422043,89.768481,147.02077,882.685521,2712.04412,-1829.358598,0.462139,1.419918,-0.957779,-237.151488,-0.124163,-33197.995195,0.862319,119,0.213318,378,0.786682,1394,0.137681,19,0.239437,0.862319,0.374803,0.907331,0.792147,0.143146,0.856854,0.207853,0.932573,0.792147,0.839188,0.907331,2.545,4.222,2.480416,3.603623,407062,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1572,338,0,82.303665,17.696335,0,0.322672,0.195329,0.377941,81.34019,131.657546,882.685521,1654.963508,-772.277987,0.462139,0.866473,-0.404334,-120.736878,-0.063213,-16901.527123,0.804348,111,0.175508,311,0.824492,1461,0.195652,27,0.263033,0.804348,0.396429,0.900203,0.823037,0.194197,0.805803,0.176963,0.929919,0.823037,0.860201,0.900203,2.786,4.958,2.667617,4.321228,496631,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1572,338,0,82.303665,17.696335,0,0.322672,0.195329,0.377941,81.34019,131.657546,882.685521,1654.963508,-772.277987,0.462139,0.866473,-0.404334,-120.736878,-0.063213,-16901.527123,0.804348,111,0.175508,311,0.824492,1461,0.195652,27,0.263033,0.804348,0.396429,0.900203,0.823037,0.194197,0.805803,0.176963,0.929919,0.823037,0.860201,0.900203,2.885,4.978,2.823618,4.243227,496673,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1586,324,0,83.036649,16.963351,0,0.332416,0.174562,0.384583,72.691971,133.971396,882.685521,11344.747003,-10462.061482,0.462139,5.939658,-5.477519,-18.54473,-0.009709,-2596.010948,0.797101,110,0.167043,296,0.832957,1476,0.202899,28,0.270936,0.797101,0.404412,0.882152,0.830366,0.200308,0.799692,0.169634,0.930052,0.830366,0.865213,0.882073,2.636,4.081,2.527216,3.697224,407022,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1586,324,0,83.036649,16.963351,0,0.332416,0.174562,0.384583,72.691971,133.971396,882.685521,11344.747003,-10462.061482,0.462139,5.939658,-5.477519,-18.54473,-0.009709,-2596.010948,0.797101,110,0.167043,296,0.832957,1476,0.202899,28,0.270936,0.797101,0.404412,0.882152,0.830366,0.200308,0.799692,0.169634,0.930052,0.830366,0.865213,0.882073,2.396,4.32,2.355615,3.588023,407064,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1612,298,0,84.397906,15.602094,0,0.344384,0.171778,0.362618,71.532744,126.319549,882.685521,8930.693347,-8048.007825,0.462139,4.675756,-4.213617,-3.73823,-0.001957,-523.301604,0.76087,105,0.149549,265,0.850451,1507,0.23913,33,0.283784,0.76087,0.413386,0.878668,0.843979,0.232658,0.767342,0.156021,0.928372,0.843979,0.874141,0.878672,2.743,5.066,2.652017,4.383628,496633,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1612,298,0,84.397906,15.602094,0,0.344384,0.171778,0.362618,71.532744,126.319549,882.685521,8930.693347,-8048.007825,0.462139,4.675756,-4.213617,-3.73823,-0.001957,-523.301604,0.76087,105,0.149549,265,0.850451,1507,0.23913,33,0.283784,0.76087,0.413386,0.878668,0.843979,0.232658,0.767342,0.156021,0.928372,0.843979,0.874141,0.878672,2.812,4.939,2.714417,4.243227,496675,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1513,397,0,79.21466,20.78534,0,0.295077,0.215569,0.422043,89.768481,147.02077,882.685521,2712.04412,-1829.358598,0.462139,1.419918,-0.957779,-237.151488,-0.124163,-33197.995195,0.862319,119,0.213318,378,0.786682,1394,0.137681,19,0.239437,0.862319,0.374803,0.907331,0.792147,0.143146,0.856854,0.207853,0.932573,0.792147,0.839188,0.907331,2.462,4.024,2.402415,3.447622,407024,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1828,3993,1910,1513,397,0,79.21466,20.78534,0,0.295077,0.215569,0.422043,89.768481,147.02077,882.685521,2712.04412,-1829.358598,0.462139,1.419918,-0.957779,-237.151488,-0.124163,-33197.995195,0.862319,119,0.213318,378,0.786682,1394,0.137681,19,0.239437,0.862319,0.374803,0.907331,0.792147,0.143146,0.856854,0.207853,0.932573,0.792147,0.839188,0.907331,2.424,4.067,2.386815,3.416422,407066,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1829,3993,1910,1572,338,0,82.303665,17.696335,0,0.322672,0.195329,0.377941,81.34019,131.657546,882.685521,1654.963508,-772.277987,0.462139,0.866473,-0.404334,-120.736878,-0.063213,-16901.527123,0.804348,111,0.175508,311,0.824492,1461,0.195652,27,0.263033,0.804348,0.396429,0.900203,0.823037,0.194197,0.805803,0.176963,0.929919,0.823037,0.860201,0.900203,2.756,4.871,2.605217,4.290028,496635,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1829,3993,1910,1572,338,0,82.303665,17.696335,0,0.322672,0.195329,0.377941,81.34019,131.657546,882.685521,1654.963508,-772.277987,0.462139,0.866473,-0.404334,-120.736878,-0.063213,-16901.527123,0.804348,111,0.175508,311,0.824492,1461,0.195652,27,0.263033,0.804348,0.396429,0.900203,0.823037,0.194197,0.805803,0.176963,0.929919,0.823037,0.860201,0.900203,2.672,4.784,2.620817,4.149627,496677,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1829,3993,1910,1485,425,0,77.748691,22.251309,0,0.238418,0.224544,0.455115,93.50603,158.541626,882.685521,21062.671139,-20179.985617,0.462139,11.027577,-10.565437,-272.599394,-0.142722,-38160.221724,0.73913,102,0.219526,389,0.780474,1383,0.26087,36,0.207739,0.73913,0.324324,0.842168,0.777487,0.257882,0.742118,0.222513,0.919221,0.777487,0.827617,0.841607,2.4,3.912,2.308815,3.291621,407026,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1829,3993,1910,1485,425,0,77.748691,22.251309,0,0.238418,0.224544,0.455115,93.50603,158.541626,882.685521,21062.671139,-20179.985617,0.462139,11.027577,-10.565437,-272.599394,-0.142722,-38160.221724,0.73913,102,0.219526,389,0.780474,1383,0.26087,36,0.207739,0.73913,0.324324,0.842168,0.777487,0.257882,0.742118,0.222513,0.919221,0.777487,0.827617,0.841607,2.438,3.913,2.277615,3.432022,407068,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1829,3993,1910,1561,349,0,81.727749,18.272251,0,0.279635,0.193138,0.410544,80.427906,143.014992,882.685521,19240.404737,-18357.719216,0.462139,10.07351,-9.611371,-103.253786,-0.05406,-14454.130998,0.702899,97,0.173815,308,0.826185,1464,0.297101,41,0.239506,0.702899,0.357274,0.835877,0.817277,0.288194,0.711806,0.182723,0.919779,0.817277,0.854757,0.835856,2.714,4.791,2.652017,4.196427,496637,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.1829,3993,1910,1561,349,0,81.727749,18.272251,0,0.279635,0.193138,0.410544,80.427906,143.014992,882.685521,19240.404737,-18357.719216,0.462139,10.07351,-9.611371,-103.253786,-0.05406,-14454.130998,0.702899,97,0.173815,308,0.826185,1464,0.297101,41,0.239506,0.702899,0.357274,0.835877,0.817277,0.288194,0.711806,0.182723,0.919779,0.817277,0.854757,0.835856,2.7,4.812,2.636417,4.134027,496679,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1651,259,0,86.439791,13.560209,0,0.413631,0.172278,0.332654,71.741084,115.881486,882.685521,1216.621532,-333.936011,0.462139,0.636975,-0.174836,-17.50251,-0.009164,-2450.114248,0.847826,117,0.134312,238,0.865688,1534,0.152174,21,0.329577,0.847826,0.474645,0.911653,0.864398,0.150883,0.849117,0.135602,0.939032,0.864398,0.889819,0.911653,0.162,0.034,0.140401,0.0156,220768,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1651,259,0,86.439791,13.560209,0,0.413631,0.172278,0.332654,71.741084,115.881486,882.685521,1216.621532,-333.936011,0.462139,0.636975,-0.174836,-17.50251,-0.009164,-2450.114248,0.847826,117,0.134312,238,0.865688,1534,0.152174,21,0.329577,0.847826,0.474645,0.911653,0.864398,0.150883,0.849117,0.135602,0.939032,0.864398,0.889819,0.911653,0.191,0.032,0.124801,0.0468,220810,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1659,251,0,86.858639,13.141361,0,0.418221,0.17226,0.325895,71.733731,113.52704,882.685521,1122.747324,-240.061803,0.462139,0.587826,-0.125687,-3.217949,-0.001685,-450.469293,0.833333,115,0.128668,228,0.871332,1544,0.166667,23,0.335277,0.833333,0.47817,0.906368,0.868586,0.163921,0.836079,0.131414,0.938356,0.868586,0.892556,0.906368,0.14,0.028,0.109201,0.0312,269509,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1659,251,0,86.858639,13.141361,0,0.418221,0.17226,0.325895,71.733731,113.52704,882.685521,1122.747324,-240.061803,0.462139,0.587826,-0.125687,-3.217949,-0.001685,-450.469293,0.833333,115,0.128668,228,0.871332,1544,0.166667,23,0.335277,0.833333,0.47817,0.906368,0.868586,0.163921,0.836079,0.131414,0.938356,0.868586,0.892556,0.906368,0.141,0.03,0.124801,0.0156,269551,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1642,268,0,85.968586,14.031414,0,0.401372,0.177941,0.339134,74.09908,118.138991,882.685521,1305.862041,-423.17652,0.462139,0.683697,-0.221558,-52.579798,-0.027529,-7360.459373,0.84058,116,0.138826,246,0.861174,1526,0.15942,22,0.320442,0.84058,0.464,0.902738,0.859686,0.157932,0.842068,0.140314,0.937716,0.859686,0.886383,0.902738,0.14,0.032,0.140401,0.0156,220770,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1642,268,0,85.968586,14.031414,0,0.401372,0.177941,0.339134,74.09908,118.138991,882.685521,1305.862041,-423.17652,0.462139,0.683697,-0.221558,-52.579798,-0.027529,-7360.459373,0.84058,116,0.138826,246,0.861174,1526,0.15942,22,0.320442,0.84058,0.464,0.902738,0.859686,0.157932,0.842068,0.140314,0.937716,0.859686,0.886383,0.902738,0.137,0.032,0.109201,0.0312,220812,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1646,264,0,86.17801,13.82199,0,0.401152,0.177185,0.333601,73.784625,116.211338,882.685521,1202.119487,-319.433966,0.462139,0.629382,-0.167243,-40.471976,-0.02119,-5665.528309,0.826087,114,0.13544,240,0.86456,1532,0.173913,24,0.322034,0.826087,0.463415,0.899904,0.86178,0.171133,0.828867,0.13822,0.936706,0.86178,0.887636,0.899904,0.186,0.031,0.124801,0.0312,269511,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1646,264,0,86.17801,13.82199,0,0.401152,0.177185,0.333601,73.784625,116.211338,882.685521,1202.119487,-319.433966,0.462139,0.629382,-0.167243,-40.471976,-0.02119,-5665.528309,0.826087,114,0.13544,240,0.86456,1532,0.173913,24,0.322034,0.826087,0.463415,0.899904,0.86178,0.171133,0.828867,0.13822,0.936706,0.86178,0.887636,0.899904,0.143,0.034,0.124801,0.0312,269553,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1397,513,0,73.141361,26.858639,0,0.219519,0.259767,0.480118,108.173645,167.25154,882.685521,6946.104998,-6063.419476,0.462139,3.636704,-3.174565,-471.38329,-0.246798,-65987.273799,0.84058,116,0.277088,491,0.722912,1281,0.15942,22,0.191104,0.84058,0.311409,0.85824,0.731414,0.167922,0.832078,0.268586,0.925892,0.731414,0.795473,0.858416,0.16,0.038,0.156001,0.0156,220772,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1397,513,0,73.141361,26.858639,0,0.219519,0.259767,0.480118,108.173645,167.25154,882.685521,6946.104998,-6063.419476,0.462139,3.636704,-3.174565,-471.38329,-0.246798,-65987.273799,0.84058,116,0.277088,491,0.722912,1281,0.15942,22,0.191104,0.84058,0.311409,0.85824,0.731414,0.167922,0.832078,0.268586,0.925892,0.731414,0.795473,0.858416,0.16,0.038,0.156001,0.0312,220814,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1397,513,0,73.141361,26.858639,0,0.207135,0.26374,0.484049,109.828285,168.620875,882.685521,6777.753755,-5895.068234,0.462139,3.548562,-3.086423,-490.92685,-0.25703,-68723.10745,0.797101,110,0.273702,485,0.726298,1287,0.202899,28,0.184874,0.797101,0.300136,0.844602,0.731414,0.208014,0.791986,0.268586,0.921352,0.731414,0.79526,0.844698,0.194,0.032,0.124801,0.0312,269513,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1397,513,0,73.141361,26.858639,0,0.207135,0.26374,0.484049,109.828285,168.620875,882.685521,6777.753755,-5895.068234,0.462139,3.548562,-3.086423,-490.92685,-0.25703,-68723.10745,0.797101,110,0.273702,485,0.726298,1287,0.202899,28,0.184874,0.797101,0.300136,0.844602,0.731414,0.208014,0.791986,0.268586,0.921352,0.731414,0.79526,0.844698,0.15,0.031,0.109201,0.0312,269555,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1393,517,0,72.931937,27.068063,0,0.221539,0.263112,0.484324,109.566725,168.716704,882.685521,7345.767997,-6463.082476,0.462139,3.845952,-3.383813,-489.644308,-0.256358,-68543.568923,0.855072,118,0.280474,497,0.719526,1275,0.144928,20,0.19187,0.855072,0.313413,0.855177,0.729319,0.154721,0.845279,0.270681,0.927283,0.729319,0.794004,0.855334,0.159,0.038,0.140401,0.0312,220774,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1393,517,0,72.931937,27.068063,0,0.221539,0.263112,0.484324,109.566725,168.716704,882.685521,7345.767997,-6463.082476,0.462139,3.845952,-3.383813,-489.644308,-0.256358,-68543.568923,0.855072,118,0.280474,497,0.719526,1275,0.144928,20,0.19187,0.855072,0.313413,0.855177,0.729319,0.154721,0.845279,0.270681,0.927283,0.729319,0.794004,0.855334,0.161,0.038,0.140401,0.0312,220816,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1394,516,0,72.984293,27.015707,0,0.203552,0.265447,0.487424,110.538886,169.796353,882.685521,7156.256968,-6273.571446,0.462139,3.746731,-3.284592,-501.472475,-0.262551,-70199.352057,0.789855,109,0.274831,487,0.725169,1285,0.210145,29,0.182886,0.789855,0.297003,0.839678,0.729843,0.214819,0.785181,0.270157,0.920487,0.729843,0.794082,0.839775,0.206,0.034,0.124801,0.0312,269515,633226,539491,?
3_Apache_Java_JFace.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.1829,3993,1910,1394,516,0,72.984293,27.015707,0,0.203552,0.265447,0.487424,110.538886,169.796353,882.685521,7156.256968,-6273.571446,0.462139,3.746731,-3.284592,-501.472475,-0.262551,-70199.352057,0.789855,109,0.274831,487,0.725169,1285,0.210145,29,0.182886,0.789855,0.297003,0.839678,0.729843,0.214819,0.785181,0.270157,0.920487,0.729843,0.794082,0.839775,0.151,0.037,0.124801,0.0312,269557,633226,539491,?

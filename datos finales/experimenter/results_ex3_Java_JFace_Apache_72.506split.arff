@relation InstanceResultListener

@attribute Key_Dataset {3_Java_JFace_Apache.arff}
@attribute Key_Run {1}
@attribute Key_Scheme {weka.classifiers.meta.FilteredClassifier}
@attribute Key_Scheme_options {'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial','-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial'}
@attribute Key_Scheme_version_ID {-4523450618538717400}
@attribute Date_time numeric
@attribute Number_of_training_instances numeric
@attribute Number_of_testing_instances numeric
@attribute Number_correct numeric
@attribute Number_incorrect numeric
@attribute Number_unclassified numeric
@attribute Percent_correct numeric
@attribute Percent_incorrect numeric
@attribute Percent_unclassified numeric
@attribute Kappa_statistic numeric
@attribute Mean_absolute_error numeric
@attribute Root_mean_squared_error numeric
@attribute Relative_absolute_error numeric
@attribute Root_relative_squared_error numeric
@attribute SF_prior_entropy numeric
@attribute SF_scheme_entropy numeric
@attribute SF_entropy_gain numeric
@attribute SF_mean_prior_entropy numeric
@attribute SF_mean_scheme_entropy numeric
@attribute SF_mean_entropy_gain numeric
@attribute KB_information numeric
@attribute KB_mean_information numeric
@attribute KB_relative_information numeric
@attribute True_positive_rate numeric
@attribute Num_true_positives numeric
@attribute False_positive_rate numeric
@attribute Num_false_positives numeric
@attribute True_negative_rate numeric
@attribute Num_true_negatives numeric
@attribute False_negative_rate numeric
@attribute Num_false_negatives numeric
@attribute IR_precision numeric
@attribute IR_recall numeric
@attribute F_measure numeric
@attribute Area_under_ROC numeric
@attribute Weighted_avg_true_positive_rate numeric
@attribute Weighted_avg_false_positive_rate numeric
@attribute Weighted_avg_true_negative_rate numeric
@attribute Weighted_avg_false_negative_rate numeric
@attribute Weighted_avg_IR_precision numeric
@attribute Weighted_avg_IR_recall numeric
@attribute Weighted_avg_F_measure numeric
@attribute Weighted_avg_area_under_ROC numeric
@attribute Elapsed_Time_training numeric
@attribute Elapsed_Time_testing numeric
@attribute UserCPU_Time_training numeric
@attribute UserCPU_Time_testing numeric
@attribute Serialized_Model_Size numeric
@attribute Serialized_Train_Set_Size numeric
@attribute Serialized_Test_Set_Size numeric
@attribute Summary string

@data

3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0614,4280,1623,1426,197,0,87.861984,12.138016,0,0.608051,0.129632,0.30241,40.228276,78.253351,1116.25843,1007.653652,108.604777,0.687775,0.620859,0.066916,608.986154,0.375223,79669.346529,0.726027,212,0.087904,117,0.912096,1214,0.273973,80,0.644377,0.726027,0.68277,0.934404,0.87862,0.240496,0.759504,0.12138,0.885318,0.87862,0.88138,0.934404,3.042,3.884,2.948419,3.322821,454632,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0614,4280,1623,1426,197,0,87.861984,12.138016,0,0.608051,0.129632,0.30241,40.228276,78.253351,1116.25843,1007.653652,108.604777,0.687775,0.620859,0.066916,608.986154,0.375223,79669.346529,0.726027,212,0.087904,117,0.912096,1214,0.273973,80,0.644377,0.726027,0.68277,0.934404,0.87862,0.240496,0.759504,0.12138,0.885318,0.87862,0.88138,0.934404,2.886,3.588,2.839218,3.16682,454674,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0614,4280,1623,1450,173,0,89.340727,10.659273,0,0.677182,0.152102,0.303984,47.201335,78.660711,1116.25843,914.531484,201.726946,0.687775,0.563482,0.124293,543.302714,0.334752,71076.447114,0.856164,250,0.098422,131,0.901578,1200,0.143836,42,0.656168,0.856164,0.742942,0.927004,0.893407,0.135665,0.864335,0.106593,0.910408,0.893407,0.898612,0.927004,2.621,3.603,2.558416,3.13562,448285,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0614,4280,1623,1450,173,0,89.340727,10.659273,0,0.677182,0.152102,0.303984,47.201335,78.660711,1116.25843,914.531484,201.726946,0.687775,0.563482,0.124293,543.302714,0.334752,71076.447114,0.856164,250,0.098422,131,0.901578,1200,0.143836,42,0.656168,0.856164,0.742942,0.927004,0.893407,0.135665,0.864335,0.106593,0.910408,0.893407,0.898612,0.927004,2.621,3.51,2.574017,3.15122,448327,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0614,4280,1623,1335,288,0,82.255083,17.744917,0,0.400263,0.178847,0.391505,55.501165,101.308038,1116.25843,11592.313041,-10476.054611,0.687775,7.142522,-6.454747,386.74304,0.238289,50594.853602,0.510274,149,0.108941,145,0.891059,1186,0.489726,143,0.506803,0.510274,0.508532,0.87654,0.822551,0.421218,0.578782,0.177449,0.823026,0.822551,0.822787,0.877382,2.901,3.541,2.808018,3.16682,454634,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1335,288,0,82.255083,17.744917,0,0.400263,0.178847,0.391505,55.501165,101.308038,1116.25843,11592.313041,-10476.054611,0.687775,7.142522,-6.454747,386.74304,0.238289,50594.853602,0.510274,149,0.108941,145,0.891059,1186,0.489726,143,0.506803,0.510274,0.508532,0.87654,0.822551,0.421218,0.578782,0.177449,0.823026,0.822551,0.822787,0.877382,2.839,3.573,2.808018,3.18242,454676,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1351,272,0,83.240912,16.759088,0,0.489398,0.194767,0.371226,60.441568,96.060645,1116.25843,11464.808128,-10348.549698,0.687775,7.063961,-6.376186,336.59063,0.207388,44033.768909,0.678082,198,0.133734,178,0.866266,1153,0.321918,94,0.526596,0.678082,0.592814,0.865369,0.832409,0.288061,0.711939,0.167591,0.853009,0.832409,0.840216,0.866153,2.637,3.51,2.589617,3.010819,448287,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1351,272,0,83.240912,16.759088,0,0.489398,0.194767,0.371226,60.441568,96.060645,1116.25843,11464.808128,-10348.549698,0.687775,7.063961,-6.376186,336.59063,0.207388,44033.768909,0.678082,198,0.133734,178,0.866266,1153,0.321918,94,0.526596,0.678082,0.592814,0.865369,0.832409,0.288061,0.711939,0.167591,0.853009,0.832409,0.840216,0.866153,2.636,3.495,2.589617,3.10442,448329,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1426,197,0,87.861984,12.138016,0,0.608051,0.129632,0.30241,40.228276,78.253351,1116.25843,1007.653652,108.604777,0.687775,0.620859,0.066916,608.986154,0.375223,79669.346529,0.726027,212,0.087904,117,0.912096,1214,0.273973,80,0.644377,0.726027,0.68277,0.934404,0.87862,0.240496,0.759504,0.12138,0.885318,0.87862,0.88138,0.934404,2.855,3.572,2.808018,3.13562,454636,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1426,197,0,87.861984,12.138016,0,0.608051,0.129632,0.30241,40.228276,78.253351,1116.25843,1007.653652,108.604777,0.687775,0.620859,0.066916,608.986154,0.375223,79669.346529,0.726027,212,0.087904,117,0.912096,1214,0.273973,80,0.644377,0.726027,0.68277,0.934404,0.87862,0.240496,0.759504,0.12138,0.885318,0.87862,0.88138,0.934404,2.902,3.541,2.839218,3.18242,454678,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1450,173,0,89.340727,10.659273,0,0.677182,0.152102,0.303984,47.201335,78.660711,1116.25843,914.531484,201.726946,0.687775,0.563482,0.124293,543.302714,0.334752,71076.447114,0.856164,250,0.098422,131,0.901578,1200,0.143836,42,0.656168,0.856164,0.742942,0.927004,0.893407,0.135665,0.864335,0.106593,0.910408,0.893407,0.898612,0.927004,2.621,3.51,2.589617,3.198021,448289,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1450,173,0,89.340727,10.659273,0,0.677182,0.152102,0.303984,47.201335,78.660711,1116.25843,914.531484,201.726946,0.687775,0.563482,0.124293,543.302714,0.334752,71076.447114,0.856164,250,0.098422,131,0.901578,1200,0.143836,42,0.656168,0.856164,0.742942,0.927004,0.893407,0.135665,0.864335,0.106593,0.910408,0.893407,0.898612,0.927004,2.621,3.51,2.558416,3.05762,448331,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1216,407,0,74.922982,25.077018,0,0.368733,0.253779,0.4903,78.754394,126.872712,1116.25843,15306.005549,-14189.74712,0.687775,9.430687,-8.742913,79.731345,0.049126,10430.687324,0.746575,218,0.250188,333,0.749812,998,0.253425,74,0.395644,0.746575,0.5172,0.817814,0.74923,0.252842,0.747158,0.25077,0.834658,0.74923,0.774238,0.818206,2.87,3.557,2.839218,3.12002,454638,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0615,4280,1623,1216,407,0,74.922982,25.077018,0,0.368733,0.253779,0.4903,78.754394,126.872712,1116.25843,15306.005549,-14189.74712,0.687775,9.430687,-8.742913,79.731345,0.049126,10430.687324,0.746575,218,0.250188,333,0.749812,998,0.253425,74,0.395644,0.746575,0.5172,0.817814,0.74923,0.252842,0.747158,0.25077,0.834658,0.74923,0.774238,0.818206,2.871,3.557,2.854818,3.18242,454680,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0616,4280,1623,1201,422,0,73.998768,26.001232,0,0.36745,0.264561,0.496619,82.100556,128.508089,1116.25843,16167.247178,-15050.988748,0.687775,9.961335,-9.273561,26.85035,0.016544,3512.641227,0.780822,228,0.268971,358,0.731029,973,0.219178,64,0.389078,0.780822,0.519362,0.796818,0.739988,0.228136,0.771864,0.260012,0.839474,0.739988,0.76738,0.797095,2.652,3.51,2.636417,3.16682,448291,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayes --',-4523450618538717400,20150824.0616,4280,1623,1201,422,0,73.998768,26.001232,0,0.36745,0.264561,0.496619,82.100556,128.508089,1116.25843,16167.247178,-15050.988748,0.687775,9.961335,-9.273561,26.85035,0.016544,3512.641227,0.780822,228,0.268971,358,0.731029,973,0.219178,64,0.389078,0.780822,0.519362,0.796818,0.739988,0.228136,0.771864,0.260012,0.839474,0.739988,0.76738,0.797095,2.637,3.494,2.620817,3.16682,448333,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1468,155,0,90.449784,9.550216,0,0.686015,0.143253,0.272294,44.455247,70.460256,1116.25843,594.217511,522.040919,0.687775,0.366123,0.321652,584.125106,0.359905,76416.951611,0.773973,226,0.066867,89,0.933133,1242,0.226027,66,0.71746,0.773973,0.744646,0.939674,0.904498,0.197392,0.802608,0.095502,0.907787,0.904498,0.905891,0.939674,0.171,0.032,0.171601,0.0312,245932,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1468,155,0,90.449784,9.550216,0,0.686015,0.143253,0.272294,44.455247,70.460256,1116.25843,594.217511,522.040919,0.687775,0.366123,0.321652,584.125106,0.359905,76416.951611,0.773973,226,0.066867,89,0.933133,1242,0.226027,66,0.71746,0.773973,0.744646,0.939674,0.904498,0.197392,0.802608,0.095502,0.907787,0.904498,0.905891,0.939674,0.187,0.015,0.156001,0.0156,245974,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1461,162,0,90.018484,9.981516,0,0.677276,0.154762,0.278488,48.026812,72.063211,1116.25843,623.377194,492.881236,0.687775,0.384089,0.303685,547.1274,0.337109,71576.803759,0.784247,229,0.07438,99,0.92562,1232,0.215753,63,0.698171,0.784247,0.73871,0.931208,0.900185,0.190318,0.809682,0.099815,0.905801,0.900185,0.902399,0.931208,0.14,0.032,0.124801,0.0312,242757,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1461,162,0,90.018484,9.981516,0,0.677276,0.154762,0.278488,48.026812,72.063211,1116.25843,623.377194,492.881236,0.687775,0.384089,0.303685,547.1274,0.337109,71576.803759,0.784247,229,0.07438,99,0.92562,1232,0.215753,63,0.698171,0.784247,0.73871,0.931208,0.900185,0.190318,0.809682,0.099815,0.905801,0.900185,0.902399,0.931208,0.171,0.016,0.156001,0,242799,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1461,162,0,90.018484,9.981516,0,0.678097,0.150134,0.282424,46.590547,73.081531,1116.25843,657.249427,459.009003,0.687775,0.40496,0.282815,552.156169,0.340207,72234.681931,0.787671,230,0.075131,100,0.924869,1231,0.212329,62,0.69697,0.787671,0.73955,0.923622,0.900185,0.187645,0.812355,0.099815,0.906157,0.900185,0.902511,0.923622,0.156,0.032,0.156001,0.0312,245934,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1461,162,0,90.018484,9.981516,0,0.678097,0.150134,0.282424,46.590547,73.081531,1116.25843,657.249427,459.009003,0.687775,0.40496,0.282815,552.156169,0.340207,72234.681931,0.787671,230,0.075131,100,0.924869,1231,0.212329,62,0.69697,0.787671,0.73955,0.923622,0.900185,0.187645,0.812355,0.099815,0.906157,0.900185,0.902511,0.923622,0.218,0.016,0.171601,0.0156,245976,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1442,181,0,88.847813,11.152187,0,0.630471,0.160214,0.287762,49.718705,74.463003,1116.25843,671.982148,444.276282,0.687775,0.414037,0.273738,516.728906,0.318379,67599.984038,0.719178,210,0.07438,99,0.92562,1232,0.280822,82,0.679612,0.719178,0.698835,0.918433,0.888478,0.24368,0.75632,0.111522,0.89118,0.888478,0.889697,0.918433,0.156,0.016,0.156001,0.0156,242759,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1442,181,0,88.847813,11.152187,0,0.630471,0.160214,0.287762,49.718705,74.463003,1116.25843,671.982148,444.276282,0.687775,0.414037,0.273738,516.728906,0.318379,67599.984038,0.719178,210,0.07438,99,0.92562,1232,0.280822,82,0.679612,0.719178,0.698835,0.918433,0.888478,0.24368,0.75632,0.111522,0.89118,0.888478,0.889697,0.918433,0.156,0.032,0.140401,0.0312,242801,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1383,240,0,85.212569,14.787431,0,0.575967,0.166225,0.367164,51.583969,95.009475,1116.25843,2704.255956,-1587.997526,0.687775,1.666208,-0.978433,442.444725,0.272609,57881.910601,0.821918,240,0.141247,188,0.858753,1143,0.178082,52,0.560748,0.821918,0.666667,0.85883,0.852126,0.171455,0.828545,0.147874,0.885287,0.852126,0.862111,0.85883,0.187,0.015,0.187201,0.0156,245936,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1383,240,0,85.212569,14.787431,0,0.575967,0.166225,0.367164,51.583969,95.009475,1116.25843,2704.255956,-1587.997526,0.687775,1.666208,-0.978433,442.444725,0.272609,57881.910601,0.821918,240,0.141247,188,0.858753,1143,0.178082,52,0.560748,0.821918,0.666667,0.85883,0.852126,0.171455,0.828545,0.147874,0.885287,0.852126,0.862111,0.85883,0.172,0.031,0.156001,0.0312,245978,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1379,244,0,84.966112,15.033888,0,0.567922,0.171616,0.370939,53.25699,95.986238,1116.25843,2763.88119,-1647.62276,0.687775,1.702946,-1.015171,424.037651,0.261268,55473.843437,0.811644,237,0.141998,189,0.858002,1142,0.188356,55,0.556338,0.811644,0.660167,0.853954,0.849661,0.180016,0.819984,0.150339,0.882498,0.849661,0.859706,0.853954,0.171,0.016,0.140401,0.0156,242761,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1379,244,0,84.966112,15.033888,0,0.567922,0.171616,0.370939,53.25699,95.986238,1116.25843,2763.88119,-1647.62276,0.687775,1.702946,-1.015171,424.037651,0.261268,55473.843437,0.811644,237,0.141998,189,0.858002,1142,0.188356,55,0.556338,0.811644,0.660167,0.853954,0.849661,0.180016,0.819984,0.150339,0.882498,0.849661,0.859706,0.853954,0.156,0.031,0.140401,0.0312,242803,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.NullStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1365,258,0,84.103512,15.896488,0,0.55326,0.17234,0.376761,53.48182,97.492933,1116.25843,2899.699166,-1783.440736,0.687775,1.786629,-1.098854,415.7021,0.256132,54383.362283,0.821918,240,0.154771,206,0.845229,1125,0.178082,52,0.538117,0.821918,0.650407,0.853617,0.841035,0.173888,0.826112,0.158965,0.880669,0.841035,0.85274,0.853617,0.187,0.031,0.156001,0.0312,245938,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -stemmer weka.core.stemmers.SnowballStemmer -M 1 -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1365,258,0,84.103512,15.896488,0,0.55326,0.17234,0.376761,53.48182,97.492933,1116.25843,2899.699166,-1783.440736,0.687775,1.786629,-1.098854,415.7021,0.256132,54383.362283,0.821918,240,0.154771,206,0.845229,1125,0.178082,52,0.538117,0.821918,0.650407,0.853617,0.841035,0.173888,0.826112,0.158965,0.880669,0.841035,0.85274,0.853617,0.187,0.031,0.171601,0.0312,245980,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.NullStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1375,248,0,84.719655,15.280345,0,0.566733,0.176766,0.379112,54.855348,98.10111,1116.25843,2954.885749,-1838.62732,0.687775,1.820632,-1.132857,402.980643,0.248294,52719.10422,0.825342,241,0.148009,197,0.851991,1134,0.174658,51,0.550228,0.825342,0.660274,0.848705,0.847197,0.169863,0.830137,0.152803,0.883785,0.847197,0.858043,0.848705,0.172,0.016,0.156001,0.0156,242763,646141,526576,?
3_Java_JFace_Apache.arff,1,weka.classifiers.meta.FilteredClassifier,'-F \"weka.filters.unsupervised.attribute.StringToWordVector -R first -W 1000 -prune-rate -1.0 -C -T -I -N 0 -L -S -stemmer weka.core.stemmers.SnowballStemmer -M 1 -stopwords C:\\\\Users\\\\gabo\\\\Documents\\\\U\\\\F\\\\TextMining\\\\stoplists\\\\stop-words-english3-google.txt -tokenizer \\\"weka.core.tokenizers.WordTokenizer -delimiters \\\\\\\" \\\\\\\\r\\\\\\\\n\\\\\\\\t.,;:\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"()?!\\\\\\\"\\\"\" -W weka.classifiers.bayes.NaiveBayesMultinomial',-4523450618538717400,20150824.0616,4280,1623,1375,248,0,84.719655,15.280345,0,0.566733,0.176766,0.379112,54.855348,98.10111,1116.25843,2954.885749,-1838.62732,0.687775,1.820632,-1.132857,402.980643,0.248294,52719.10422,0.825342,241,0.148009,197,0.851991,1134,0.174658,51,0.550228,0.825342,0.660274,0.848705,0.847197,0.169863,0.830137,0.152803,0.883785,0.847197,0.858043,0.848705,0.156,0.031,0.140401,0.0156,242805,646141,526576,?
